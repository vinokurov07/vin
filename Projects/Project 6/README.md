# PROJECT-6. Предсказание совершения покупки в интернет-магазине

## Оглавление  
[1. Описание проекта](README.md#Описание-проекта)  
[2. Краткая информация о данных](README.md#Краткая-информация-о-данных)  
[3. Этапы работы над проектом](README.md#Этапы-работы-над-проектом)  
[4. Результаты](README.md#Результаты)    
[5. Выводы](README.md#Выводы) 

### Описание проекта  

Бизнес-задача: будем пытаться предсказать совершение покупки пользователем во время его сессии на сайте некоторого интернет-магазина. 

Техническая задача: построить модель машинного обучения, которая на основе предложенных характеристик клиента будет предсказывать,совершит он покупку в интерент-магазине или нет.

:arrow_up:[к оглавлению](README.md#Оглавление)


### Краткая информация о данных

Набор данных состоит из векторов признаков, относящихся к 12 330 сеансам.
Набор данных был сформирован таким образом, чтобы каждый сеанс принадлежал разным пользователям в течение года, чтобы избежать какой-либо зависимости от конкретной кампании, особого дня, профиля пользователя или периода.

***Имеющиеся данные:***

Набор данных состоит из 10 числовых и 8 категориальных атрибутов.
Атрибут «Доход» может использоваться в качестве метки класса.

«Административные», «Продолжительность административного», «Информационные», «Продолжительность информационного», «Связанные с продуктом» и «Продолжительность, связанная с продуктом» представляют собой количество различных типов страниц, посещённых посетителем за сеанс, и общее время, проведённое на каждой из этих категорий страниц. Значения этих характеристик определяются на основе URL-адресов страниц, посещённых пользователем, и обновляются в режиме реального времени при каждом действии пользователя, например, при переходе с одной страницы на другую. Показатели «Показатель отказов», «Показатель выходов» и «Ценность страницы» представляют собой метрики, измеряемые Google Analytics для каждой страницы сайта электронной коммерции. Значение показателя «Показатель отказов» для веб-страницы относится к проценту посетителей, которые переходят на сайт с этой страницы, а затем покидают её («отказ»), не инициируя никаких других запросов к серверу аналитики в течение данного сеанса. Значение показателя «Показатель выходов» для конкретной веб-страницы рассчитывается как процент последних просмотров страницы за сеанс. Атрибут «Значение страницы» представляет собой среднее значение для веб-страницы, которую пользователь посетил перед совершением транзакции электронной торговли. Атрибут «Особый день» указывает на близость времени посещения сайта к определённому особому дню (например, Дню матери, Дню святого Валентина), в который сеансы с большей вероятностью завершатся транзакцией. Значение этого атрибута определяется с учётом динамики электронной торговли, такой как продолжительность между датой заказа и датой доставки. Например, для Дня святого Валентина это значение принимает ненулевое значение в период с 2 по 12 февраля, нулевое значение до и после этой даты, если только она не близка к другому особому дню, и максимальное значение 1 8 февраля. Набор данных также включает операционную систему, браузер, регион, тип трафика, тип посетителя (повторяющийся или новый), логическое значение, указывающее, является ли дата посещения выходным днём, и месяц года

  
:arrow_up:[к оглавлению](README.md#Оглавление)


### Этапы работы над проектом  

1. Первичная обработка данных

    В рамках этой части обработаем пропуски и выбросы в данных. Это необходимо для дальнейшей работы с ними.

2. Разведывательный анализ данных (EDA)

    Необходимо будет исследовать данные, проверить распределение целевой переменной.

3. Построение модели случайного леса, кросс-валидация

    Решим задачу методом построения модели случайного леса. Оценим качество такой модели с помощью кросс-валидации по пяти фолдам.

4. Построение кривых обучения

    Использовать несколько вариаций случайного леса и с помощью кривых обучения выберем наилучшую из них..

5. Обучение модели на лучших параметрах

    Обучим случайный лес с выбранной на предыдущем этапе оптимальной глубиной на тренировочной выборке. Сделаем предсказание меток классов и выведем отчёт о метриках классификации.

6. Подбор порога вероятности с помощью PR-кривой.

    Попробуем повысить качество распознавания посетителей, совершивших покупку. Используем метод подбора порога вероятности с помощью PR-кривой. Порог вероятности будем подбирать с помощью кросс-валидации.


:arrow_up:[к оглавлению](README.md#Оглавление)


### Результаты
[Весь проект выполнен в ноутбуке](</Projects/Project 6/Project 6.ipynb>)


:arrow_up:[к оглавлению](README.md#Оглавление)


### Выводы:  

Вывод: итак, в ходе работы были выполнены все этапы проекта.

1. Первичная обработка данных.
Данные были чистыми, пропусков и выбросов нет, категориальные признаки были закодированы для подачи в модель.

2. Разведывательный анализ данных (EDA).
Итак, нам необходимо предсказать целевую переменную Revenue — признак покупки. Целевой признак является бинарным категориальным, то есть мы решаем задачу бинарной классификации. Из 12 330 сессий покупкой товара завершаются лишь 15.47 %. Мы знаем, что такое соотношение классов заставляет нас смотреть на метрики для каждого из классов отдельно.
Лучшей будет считаться та модель, у которой значение метрики  для пользователей, совершивших покупку, будет наибольшим.
Разделим выборку на тренировочную и тестовую.
Будем проводить кросс-валидацию на тренировочной выборке (то есть будем делить её на тренировочные и валидационные фолды и считать среднее значение метрики по фолдам).

3. Построение модели случайного леса, кросс-валидация

Была построена модель случаного леса без установки ниперпараметров. С помощью кросс-вадидации со стротификацией (т.к. целевая переменная распределена неравномерно) были получены метрики. Модель предсказуемо ушла в переобучение, т.к. метрики на тренировоовчных даннных идеальны, а на тестовх далеки от них.

4. Построение кривых обучения
Построены модели трех вариаций случайного леса и с помощью кривых обучения была выбрана наилучшая из них.

Создан список из трёх следующих моделей:

Случайный лес из деревьев максимальной глубины 5.
Случайный лес из деревьев максимальной глубины 7.
Случайный лес из деревьев максимальной глубины 12.

Для всех трёх моделей количество деревьев в лесу (n_estimators) принято равным 200, количество объектов в листе (min_samples_leaf) — 5. Параметр random_state = 42. Остальные параметры по умолчанию.

Построена кривую обучения для каждой из моделей.

Для построения кривых используем обучающий набор данных (X_train, y_train), стратифицированный кросс-валидатор на пяти фолдов (StratifiedKFold) и метрику F1-score. Остальные параметры функции learning_curve() по умолчанию.

Благодаря построенным графикам мы можем легко сравнить три представленные модели между собой. 

* Первый график построен для модели c максимальной глубиной дерева 5. Тренировочная и валидационная кривые постепенно сходятся к единой отметке качества, но результат низкий.
* Третий график построен для модели c максимальной глубиной дерева 12 указывает на наличие переобучения: тренировочная кривая находится на высоком уроывне, а вот валидационная кривая не может достичь такой высокой отметки.
* Из всех представленных оптимальной является модель дерева решений с ограничениями, кривая обучения которой изображена на втором графике. Тренировочная и валидационная кривые постепенно сходятся к единой отметке качества, и полученная метрика превышает отметку в 0.5.

5. Обучение модели на лучших параметрах
Используем вторую модель для обучения и предсказания.
Метрики качества составили - AUC: 0.9179, GINI: 0.8358


6. Подбор порога вероятности с помощью PR-кривой. 
С помощью построения PR-кривой, где порог вероятности был подобран с помощью кросс-валидации, получилось найти оптимальный порог вероятности, метрики precision и recall.

**Вывод:**

Отличный результат. 
* *Recall*   
Подобрав оптимальный порог вероятности мы смогли повысить recall  с 0.49 до до 0.69 для пользователей, которые совершат покупку. О чем это говорит? Мы увеличили охват, т.е. из всех пользователей, совершивших покупку, модель верно определяет 69%. Это ниже, чем этот показатель для пользователей, не совершивших покупку, но и выборка несбалансирована (85% False против 15% True). Модели "выгоднее" с точки зрения общей точности (accuracy) предсказать более частый класс (False), чем рисковать и ошибиться с редким классом (True). В результате модель жертвует Recall в пользу Precision. 
* *Precision*   
Но сдвинув порог вероятности отнесения к Тrue мы повысили охват. Да, точность снизилась с 0.79 до 0.64, но это закономерный процесс. Стало больше значений, из которых нужно выбирать True Positive.
* *F1-score*  
F1-score вырос с 0.60 до 0.67 Это подтверждает, что баланс между Precision и Recall стал значительно лучше. Модель стала более сбалансированной и эффективной.
Раньше: Модель пропускала 51% покупателей, но мы были очень уверены в тех, кого находили
Теперь: Пропускаем только 31% покупателей, при этом все еще достаточно точно определяем потенциальных клиентов
Для маркетинговых кампаний это означает:
  * Мы охватываем на 40% больше реальных покупателей [(69-49)/49]
  * При этом из каждых 100 пользователей, которых модель определит как совершивших покупку, 64 действительно совершат покупку.
* *PR-AUC* = 0.75 означает, что ваша модель в среднем на 75% эффективна в обнаружении покупателей по сравнению с идеальной моделью, и в 5 раз лучше случайного угадывания (0.75 vs 0.15).
* *AUC-ROC* = 0.9179 означает, что если взять случайного покупателя и случайного непокупателя, то в 91.79% случаев модель присвоит покупателю более высокую вероятность, чем непокупателю.


:arrow_up:[к оглавлению](README.md#Оглавление)

